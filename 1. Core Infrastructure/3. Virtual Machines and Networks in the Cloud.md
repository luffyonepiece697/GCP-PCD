# Virtual Private Cloud Networking

* We’re going to explore how Google Compute Engine works with a focus on virtual networking.
* Many users start with Google Cloud by defining their own virtual private cloud inside their first Google Cloud project 
  or by starting with the default virtual private cloud.
* A virtual private cloud, or VPC, is a secure, individual, private cloud-computing model hosted within a public cloud – like Google Cloud!
* On a VPC, customers can run code, store data, host websites, and do anything else they could do in an 
  ordinary private cloud, but this private cloud is hosted remotely by a public cloud provider.
* This means that VPCs combine the scalability and convenience of public cloud computing with the data isolation of private cloud computing.
* VPC networks connect Google Cloud resources to each other and to the internet.
* This includes segmenting networks, using firewall rules to restrict access to instances, and creating static routes to forward traffic to specific destinations.
* Here's something that tends to surprise a lot of new Google Cloud users: Google VPC networks are global.
* They can also have subnets, which is a segmented piece of the larger network, in any Google Cloud region worldwide.
* Subnets can span the zones that make up a region.
* This architecture makes it easy to define network layouts with global scope.
* Resources can even be in different zones on the same subnet.
* The size of a subnet can be increased by expanding the range of IP addresses allocated to it, and doing so won’t affect virtual machines that are already configured.
* For example, let’s take a VPC network named vpc1 that has two subnets defined in the asia-east1 and us-east1 regions.
* If the VPC has three Compute Engine VMs attached to it, it means they’re neighbors on the same subnet even though they’re in different zones.
* This capability can be used to build solutions that are resilient to disruptions yet retain a simple network layout.

# Compute Engine

* With Compute Engine, users can create and run virtual machines on Google infrastructure.
* Thousands of virtual CPUs can run on a system that’s designed to be fast and to offer consistent performance.
* Each virtual machine contains the power and functionality of a full-fledged operating system.
* This means a virtual machine can be configured much like a physical server: by specifying the amount
  of CPU power and memory needed, the amount and type of storage needed, and the operating system.
* A virtual machine instance can be created via the Google Cloud console, which is a web-based
  tool to manage Google Cloud projects and resources, the Google Cloud CLI, or the Compute Engine API.
* The instance can run Linux and Windows Server images provided by Google or any customized versions of these images.
* You can also build and run images of other operating systems and flexibly reconfigure virtual machines.
* A quick way to get started with Google Cloud is through the Cloud Marketplace, which offers solutions from both Google and third-party vendors.
* With these solutions, there’s no need to manually configure the software, virtual machine instances, storage, or network settings, 
  although many of them can be modified before launch if that’s required.
  
* Most software packages in Cloud Marketplace are available at no additional charge beyond the normal usage fees for Google Cloud resources.
* Some Cloud Marketplace images charge usage fees, particularly those published by third parties, with commercially licensed software, 
  but they all show estimates of their monthly charges before they’re launched.

* For the use of virtual machines, Compute Engine bills by the second with a one-minute minimum, and sustained-use discounts start to apply 
  automatically to virtual machines the longer they run.
* So, for each VM that runs for more than 25% of a month, Compute Engine automatically applies a discount for every additional minute.
* Compute Engine also offers committed-use discounts.
* This means that for stable and predictable workloads, a specific amount of vCPUs and memory can be purchased for up to
  a 57% discount off of normal prices in return for committing to a usage term of one year or three years.
  
* And then there are Preemptible and Spot VMs.
* Let’s say you have a workload that doesn’t require a human to sit and wait for it to finish–such as a batch job analyzing a large dataset.
* You can save money, in some cases up to 90%, by choosing Preemptible or Spot VMs to run the job.
* A Preemptible or Spot VM is different from an ordinary Compute Engine VM in only one respect: 
  Compute Engine VM has permission to terminate a job if its resources are needed elsewhere.
* Although savings are possible with preemptible or spot VMs, you'll need to ensure that your job can be stopped and restarted.
* Spot VMs differ from Preemptible VMs by offering more features.
* For example, preemptible VMs can only run for up to 24 hours at a time, but Spot VMs do not have a maximum runtime.
* However, the pricing is, currently the same for both.
* In terms of storage, Compute Engine doesn’t require a particular option or machine type to get high throughput between processing and persistent disks.
* That’s the default, and it comes to you at no extra cost.
* And finally, you’ll only pay for what you need with custom machine types.
* Compute Engine lets you choose the machine properties of your instances, like the number of virtual CPUs and the
  amount of memory, by using a set of predefined machine types or by creating your own custom machine types.


# Scaling Virtual Machines

* With Compute Engine, you can choose the most appropriate machine properties for your instances, like the number of 
  virtual CPUs and the amount of memory, by using a set of predefined machine types, or by creating custom machine types.
* To do this, Compute Engine has a feature called Autoscaling, where VMs can be added to or subtracted from an application based on load metrics.
* The other part of making that work is balancing the incoming traffic among the VMs.
* Google’s Virtual Private Cloud (VPC) supports several different kinds of load balancing.
* With Compute Engine, you can in fact configure very large VMs, which are great for workloads such as in-memory databases 
  and CPU-intensive analytics, but most Google Cloud customers start off with scaling out, not up.
* The maximum number of CPUs per VM is tied to its “machine family” and is also constrained by the quota available to the user, which is zone-dependent.


# Important VPC Compatibilities

* Much like physical networks, VPCs have routing tables.
* VPC routing tables are built-in so you don’t have to provision or manage a router.
* They’re used to forward traffic from one instance to another within the same network, across subnetworks, or even between 
  Google Cloud zones, without requiring an external IP address.
* Another thing you don’t have to provision or manage for Google Cloud is a firewall.
* VPCs provide a global distributed firewall, which can be controlled to restrict access to instances through both incoming and outgoing traffic.
* Firewall rules can be defined through network tags on Compute Engine instances, which is really convenient.
* For example, you can tag all your web servers with, say, “WEB,” and write a firewall rule saying that traffic on
  ports 80 or 443 is allowed into all VMs with the “WEB” tag, no matter what their IP address happens to be.
* You’ll remember that VPCs belong to Google Cloud projects, but what if your company has several Google Cloud projects, and the VPCs need to talk to each other?
* With VPC Peering, a relationship between two VPCs can be established to exchange traffic.

* Alternatively, to use the full power of Identity Access Management (IAM) to control who and what in one project can interact with a 
  VPC in another, you can configure a Shared VPC.
  

# Cloud Load Balancing

* We explored how virtual machines can autoscale to respond to changing loads.
* But how do your customers get to your application when it might be provided by four VMs one moment, and by 40 VMs at another?
* That’s done through Cloud Load Balancing.
* The job of a load balancer is to distribute user traffic across multiple instances of an application.
* By spreading the load, load balancing reduces the risk that applications experience performance issues.
* Cloud Load Balancing is a fully distributed, software-defined, managed service for all your traffic.
* And because the load balancers don’t run in VMs that you have to manage, you don’t have to worry about scaling or managing them.
* You can put Cloud Load Balancing in front of all of your traffic: HTTP or HTTPS, other TCP and SSL traffic, and UDP traffic too.
* Cloud Load Balancing provides cross-region load balancing, including automatic multi-region failover, which gently moves traffic 
  in fractions if backends become unhealthy.
* Cloud Load Balancing reacts quickly to changes in users, traffic, network, backend health, and other related conditions.
* And what if you anticipate a huge spike in demand?
* Say, your online game is already a hit; do you need to file a support ticket to warn Google of the incoming load?
* No so-called “pre-warming” is required.

* Google Cloud offers a range of load balancing solutions that can be classified based on the OSI model layer they operate at and their specific functionalities.

    1. Application Load Balancers operate at the application layer and are designed to handle HTTP and HTTPS traffic,
       making them ideal for web applications and services that require advanced features like content-based routing and SSL/TLS termination.
       * Application Load Balancers operate as reverse proxies, distributing incoming traffic across multiple backend instances based on rules you define.
       * They are highly flexible and can be configured for both internet-facing (external) and internal applications.
       
    2. Network Load Balancers operate at the transport layer and efficiently handle TCP, UDP, and other IP protocols.
       * They can be further classified into two types: 
       
        i. Proxy Network Load Balancers also function as reverse proxies, terminating client connections and establishing new ones to backend services.
           * They offer advanced traffic management capabilities and support backends located both on-premises and in various cloud environments.
           
        ii. Unlike proxy Network Load Balancers, passthrough Network Load Balancers do not modify or terminate connections.
            * Instead, they directly forward traffic to the backend while preserving the original source IP address.
            * This type is well-suited for applications that require direct server return or need to handle a wider range of IP protocols.


# Cloud DNS and Cloud CDN

* One of the most famous free Google services is 8.8.8.8, which provides a public Domain Name Service to the world.
* DNS is what translates internet hostnames to addresses, and as you might imagine, Google has a highly developed DNS infrastructure.
* It makes 8.8.8.8 available so that everyone can take advantage of it.
* But what about the internet hostnames and addresses of applications built in Google Cloud?
* Google Cloud offers Cloud DNS to help the world find them.
* It’s a managed DNS service that runs on the same infrastructure as Google.
* It has low latency and high availability, and it’s a cost-effective way to make your applications and services available to your users.
* The DNS information you publish is served from redundant locations around the world.
* Cloud DNS is also programmable.
* You can publish and manage millions of DNS zones and records using the Cloud console, the command-line interface, or the API.
* Google also has a global system of edge caches.
* Edge caching refers to the use of caching servers to store content closer to end users.
* You can use this system to accelerate content delivery in your application by using Cloud CDN - Content Delivery Network.
* This means your customers will experience lower network latency, the origins of your content will experience reduced load, and you can even save money.
* After an Application Load Balancer is set up, Cloud CDN can be enabled with a single checkbox.






















