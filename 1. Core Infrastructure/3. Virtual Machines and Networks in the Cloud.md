# Virtual Private Cloud Networking

* We’re going to explore how Google Compute Engine works with a focus on virtual networking.
* Many users start with Google Cloud by defining their own virtual private cloud inside their first Google Cloud project 
  or by starting with the default virtual private cloud.
* A virtual private cloud, or VPC, is a secure, individual, private cloud-computing model hosted within a public cloud – like Google Cloud!
* On a VPC, customers can run code, store data, host websites, and do anything else they could do in an 
  ordinary private cloud, but this private cloud is hosted remotely by a public cloud provider.
* This means that VPCs combine the scalability and convenience of public cloud computing with the data isolation of private cloud computing.
* VPC networks connect Google Cloud resources to each other and to the internet.
* This includes segmenting networks, using firewall rules to restrict access to instances, and creating static routes to forward traffic to specific destinations.
* Here's something that tends to surprise a lot of new Google Cloud users: Google VPC networks are global.
* They can also have subnets, which is a segmented piece of the larger network, in any Google Cloud region worldwide.
* Subnets can span the zones that make up a region.
* This architecture makes it easy to define network layouts with global scope.
* Resources can even be in different zones on the same subnet.
* The size of a subnet can be increased by expanding the range of IP addresses allocated to it, and doing so won’t affect virtual machines that are already configured.
* For example, let’s take a VPC network named vpc1 that has two subnets defined in the asia-east1 and us-east1 regions.
* If the VPC has three Compute Engine VMs attached to it, it means they’re neighbors on the same subnet even though they’re in different zones.
* This capability can be used to build solutions that are resilient to disruptions yet retain a simple network layout.

# Compute Engine

* With Compute Engine, users can create and run virtual machines on Google infrastructure.
* Thousands of virtual CPUs can run on a system that’s designed to be fast and to offer consistent performance.
* Each virtual machine contains the power and functionality of a full-fledged operating system.
* This means a virtual machine can be configured much like a physical server: by specifying the amount
  of CPU power and memory needed, the amount and type of storage needed, and the operating system.
* A virtual machine instance can be created via the Google Cloud console, which is a web-based
  tool to manage Google Cloud projects and resources, the Google Cloud CLI, or the Compute Engine API.
* The instance can run Linux and Windows Server images provided by Google or any customized versions of these images.
* You can also build and run images of other operating systems and flexibly reconfigure virtual machines.
* A quick way to get started with Google Cloud is through the Cloud Marketplace, which offers solutions from both Google and third-party vendors.
* With these solutions, there’s no need to manually configure the software, virtual machine instances, storage, or network settings, 
  although many of them can be modified before launch if that’s required.
  
* Most software packages in Cloud Marketplace are available at no additional charge beyond the normal usage fees for Google Cloud resources.
* Some Cloud Marketplace images charge usage fees, particularly those published by third parties, with commercially licensed software, 
  but they all show estimates of their monthly charges before they’re launched.

* For the use of virtual machines, Compute Engine bills by the second with a one-minute minimum, and sustained-use discounts start to apply 
  automatically to virtual machines the longer they run.
* So, for each VM that runs for more than 25% of a month, Compute Engine automatically applies a discount for every additional minute.
* Compute Engine also offers committed-use discounts.
* This means that for stable and predictable workloads, a specific amount of vCPUs and memory can be purchased for up to
  a 57% discount off of normal prices in return for committing to a usage term of one year or three years.
  
* And then there are Preemptible and Spot VMs.
* Let’s say you have a workload that doesn’t require a human to sit and wait for it to finish–such as a batch job analyzing a large dataset.
* You can save money, in some cases up to 90%, by choosing Preemptible or Spot VMs to run the job.
* A Preemptible or Spot VM is different from an ordinary Compute Engine VM in only one respect: 
  Compute Engine VM has permission to terminate a job if its resources are needed elsewhere.
* Although savings are possible with preemptible or spot VMs, you'll need to ensure that your job can be stopped and restarted.
* Spot VMs differ from Preemptible VMs by offering more features.
* For example, preemptible VMs can only run for up to 24 hours at a time, but Spot VMs do not have a maximum runtime.
* However, the pricing is, currently the same for both.
* In terms of storage, Compute Engine doesn’t require a particular option or machine type to get high throughput between processing and persistent disks.
* That’s the default, and it comes to you at no extra cost.
* And finally, you’ll only pay for what you need with custom machine types.
* Compute Engine lets you choose the machine properties of your instances, like the number of virtual CPUs and the
  amount of memory, by using a set of predefined machine types or by creating your own custom machine types.


# Scaling Virtual Machines

* With Compute Engine, you can choose the most appropriate machine properties for your instances, like the number of 
  virtual CPUs and the amount of memory, by using a set of predefined machine types, or by creating custom machine types.
* To do this, Compute Engine has a feature called Autoscaling, where VMs can be added to or subtracted from an application based on load metrics.
* The other part of making that work is balancing the incoming traffic among the VMs.
* Google’s Virtual Private Cloud (VPC) supports several different kinds of load balancing.
* With Compute Engine, you can in fact configure very large VMs, which are great for workloads such as in-memory databases 
  and CPU-intensive analytics, but most Google Cloud customers start off with scaling out, not up.
* The maximum number of CPUs per VM is tied to its “machine family” and is also constrained by the quota available to the user, which is zone-dependent.


# Important VPC Compatibilities

* Much like physical networks, VPCs have routing tables.
* VPC routing tables are built-in so you don’t have to provision or manage a router.
* They’re used to forward traffic from one instance to another within the same network, across subnetworks, or even between 
  Google Cloud zones, without requiring an external IP address.
* Another thing you don’t have to provision or manage for Google Cloud is a firewall.
* VPCs provide a global distributed firewall, which can be controlled to restrict access to instances through both incoming and outgoing traffic.
* Firewall rules can be defined through network tags on Compute Engine instances, which is really convenient.
* For example, you can tag all your web servers with, say, “WEB,” and write a firewall rule saying that traffic on
  ports 80 or 443 is allowed into all VMs with the “WEB” tag, no matter what their IP address happens to be.
* You’ll remember that VPCs belong to Google Cloud projects, but what if your company has several Google Cloud projects, and the VPCs need to talk to each other?
* With VPC Peering, a relationship between two VPCs can be established to exchange traffic.

* Alternatively, to use the full power of Identity Access Management (IAM) to control who and what in one project can interact with a 
  VPC in another, you can configure a Shared VPC.
  

# Cloud Load Balancing

* We explored how virtual machines can autoscale to respond to changing loads.
* But how do your customers get to your application when it might be provided by four VMs one moment, and by 40 VMs at another?
* That’s done through Cloud Load Balancing.
* The job of a load balancer is to distribute user traffic across multiple instances of an application.
* By spreading the load, load balancing reduces the risk that applications experience performance issues.
* Cloud Load Balancing is a fully distributed, software-defined, managed service for all your traffic.
* And because the load balancers don’t run in VMs that you have to manage, you don’t have to worry about scaling or managing them.
* You can put Cloud Load Balancing in front of all of your traffic: HTTP or HTTPS, other TCP and SSL traffic, and UDP traffic too.
* Cloud Load Balancing provides cross-region load balancing, including automatic multi-region failover, which gently moves traffic 
  in fractions if backends become unhealthy.
* Cloud Load Balancing reacts quickly to changes in users, traffic, network, backend health, and other related conditions.
* And what if you anticipate a huge spike in demand?
* Say, your online game is already a hit; do you need to file a support ticket to warn Google of the incoming load?
* No so-called “pre-warming” is required.

* Google Cloud offers a range of load balancing solutions that can be classified based on the OSI model layer they operate at and their specific functionalities.

    1. Application Load Balancers operate at the application layer and are designed to handle HTTP and HTTPS traffic,
       making them ideal for web applications and services that require advanced features like content-based routing and SSL/TLS termination.
       * Application Load Balancers operate as reverse proxies, distributing incoming traffic across multiple backend instances based on rules you define.
       * They are highly flexible and can be configured for both internet-facing (external) and internal applications.
       
    2. Network Load Balancers operate at the transport layer and efficiently handle TCP, UDP, and other IP protocols.
       * They can be further classified into two types: 
       
        i. Proxy Network Load Balancers also function as reverse proxies, terminating client connections and establishing new ones to backend services.
           * They offer advanced traffic management capabilities and support backends located both on-premises and in various cloud environments.
           
        ii. Unlike proxy Network Load Balancers, passthrough Network Load Balancers do not modify or terminate connections.
            * Instead, they directly forward traffic to the backend while preserving the original source IP address.
            * This type is well-suited for applications that require direct server return or need to handle a wider range of IP protocols.


# Cloud DNS and Cloud CDN

* One of the most famous free Google services is 8.8.8.8, which provides a public Domain Name Service to the world.
* DNS is what translates internet hostnames to addresses, and as you might imagine, Google has a highly developed DNS infrastructure.
* It makes 8.8.8.8 available so that everyone can take advantage of it.
* But what about the internet hostnames and addresses of applications built in Google Cloud?
* Google Cloud offers Cloud DNS to help the world find them.
* It’s a managed DNS service that runs on the same infrastructure as Google.
* It has low latency and high availability, and it’s a cost-effective way to make your applications and services available to your users.
* The DNS information you publish is served from redundant locations around the world.
* Cloud DNS is also programmable.
* You can publish and manage millions of DNS zones and records using the Cloud console, the command-line interface, or the API.
* Google also has a global system of edge caches.
* Edge caching refers to the use of caching servers to store content closer to end users.
* You can use this system to accelerate content delivery in your application by using Cloud CDN - Content Delivery Network.
* This means your customers will experience lower network latency, the origins of your content will experience reduced load, and you can even save money.
* After an Application Load Balancer is set up, Cloud CDN can be enabled with a single checkbox.

# Connecting networks to Google VPC

* Many Google Cloud customers want to connect their Google Virtual Private Cloud networks to other networks in their system, such as on-premises
  networks or networks in other clouds.
* There are several effective ways to accomplish this :-
  1. Cloud VPN
     * Start with a Virtual Private Network connection over the internet and use Cloud VPN to create a “tunnel” connection.
     * To make the connection dynamic, a Google Cloud feature called Cloud Router can be used.
     * Cloud Router lets other networks and Google VPC, exchange route information over the VPN using the Border Gateway Protocol.
     * Using this method, if you add a new subnet to your Google VPC, your on-premises network will automatically get routes to it.
     * But using the internet to connect networks isn't always the best option for everyone, either because of security concerns or because of
       bandwidth reliability.
       
  2. Direct Peering
     * A second option is to consider “peering” with Google using Direct Peering.
     * Peering means putting a router in the same public data center as a Google point of presence and using it to exchange traffic between networks.
     * Google has more than 100 points of presence around the world.
       
  3. Carrier Peering
     * Customers who aren’t already in a point of presence can work with a partner in the Carrier Peering program to get connected.
     * Carrier Peering gives you direct access from your on-premises network through a service provider's network to Google
     * Workspace and to Google Cloud products that can be exposed through one or more public IP addresses.
     * One downside of peering though, is that it isn’t covered by a Google Service Level Agreement.
       
  4. Dedicated Interconnect
     * If getting the highest uptimes for interconnection is important, using Dedicated Interconnect would be a good solution.
     * This option allows for one or more direct, private connections to Google.
     * If these connections have topologies that meet Google’s specifications, they can also be covered by an SLA of up to 99.99%.
     * Also, these connections can be backed up by a VPN for even greater reliability.
       
  5. Partner Interconnect
     * Another option we’ll explore is Partner Interconnect, which provides connectivity between an on-premises network and a VPC network through
       a supported service provider.
     * A Partner Interconnect connection is useful if a data center is in a physical location that can't reach a Dedicated Interconnect colocation facility,
       or if the data needs don’t warrant an entire 10 Gigabytes per second connection.
     * Depending on availability needs, Partner Interconnect can be configured to support mission-critical services or applications that can
       tolerate some downtime.
     * If these connections have topologies that meet Google’s specifications, they can be covered by an SLA of up to 99.99%, but note that Google
       isn’t responsible for any aspects of Partner Interconnect provided by the third-party service provider, nor any issues outside of Google's network.
  
  6. Cross-Cloud Interconnect
     * Cross-Cloud Interconnect helps you establish high-bandwidth dedicated connectivity between Google Cloud and another cloud service provider.
     * Google provisions a dedicated physical connection between the Google network and that of another cloud service provider.
     * You can use this connection to peer your Google Virtual Private Cloud network with your network that's hosted by a supported cloud service provider.
     * Cross-Cloud Interconnect supports your adoption of an integrated multicloud strategy.
     * In addition to supporting various cloud service providers, Cross-Cloud Interconnect offers reduced complexity, site-to-site data transfer, and encryption.
     * Cross-Cloud Interconnect connections are available in two sizes: 10 gigabits per second, or 100 gigabits per second.


* Choosing a network option depends on your applications and business requirements.
* You can assess those requirements by answering three simple questions.
    1. Do any of your on-premises servers or user computers with private addressing need to connect to Google Cloud resources with private addressing?
    2. Do the bandwidth and performance of your current connection to Google services currently meet your business requirements?
    3. And do you already have, or are you willing to install and manage, access and routing equipment in one of Google’s point of presence locations?

* If you need private-to-private connectivity and your internet connection meets your business requirements, then building a Cloud VPN is your best bet.
* If you don’t need private access and your Internet connection is meeting your business requirements, then you can simply use public IP addresses to
  connect to Google services.
* If you don’t need private address connectivity and your current connection to Google Cloud isn’t performing well, then peering may be your best
  connectivity option.
* Direct Peering is a good option if you already have a footprint in one of Google’s points of presence, or you’re willing to lease co-location space
  and install and support routing equipment.
* If installing equipment isn’t an option, or you would prefer to work with a service provider partner as an intermediary to peer with Google,
  then Carrier Peering is the way to go.
* If you need private, high-performance connectivity to Google Cloud, but installing equipment isn’t an option, or you would prefer to work with a
  service provider partner as an intermediary, then Partner Interconnect would be the recommended option.
* Last but not least, there’s Dedicated Interconnect, which provides you with a private circuit direct to Google.
* This is a good option if you already have a footprint or are willing to lease co-lo space and install and support routing equipment, in a
  Google point of presence(Pop).

















